{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U pymoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from data_preprocess import *\n",
    "from run_ga import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tet_path = \"./data/tet.json\"\n",
    "fdr_path = \"./data/all_class_mutation/Chart-1_fdr.json\"\n",
    "\n",
    "with open(tet_path, 'r') as f:\n",
    "    tet_data = json.load(f)\n",
    "\n",
    "\n",
    "with open(fdr_path, 'r') as f:\n",
    "    fdr_data = json.load(f)\n",
    "\n",
    "chart_1_tet = tet_data['Chart-1']\n",
    "chart_1_fdr = dict()\n",
    "\n",
    "for key, value in fdr_data['Chart_1'].items():\n",
    "    chart_1_fdr[key] = value['mutation-score']\n",
    "\n",
    "\n",
    "chart_1_tet = sorted(chart_1_tet.items())\n",
    "chart_1_fdr = sorted(chart_1_fdr.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Method: min_max\n"
     ]
    }
   ],
   "source": [
    "tests = [i[0] for i in chart_1_tet]\n",
    "execution_times = np.array([i[1] for i in chart_1_tet])\n",
    "fault_detections = np.array([i[1] for i in chart_1_fdr])\n",
    "\n",
    "test_cases = np.column_stack((execution_times, fault_detections))\n",
    "adequacy_scores = get_adequacy_scores(fault_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using 1/N Mutation \n",
      "Mean execution Time 5.354044444444446\n",
      "Mean Fault Detection Rate 2.1805153515536633\n"
     ]
    }
   ],
   "source": [
    "bitflip = run_nsga(test_cases, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Using Adequacy Score\n",
      "Mean execution Time 5.319666666666667\n",
      "Mean Fault Detection Rate 2.073650441112962\n"
     ]
    }
   ],
   "source": [
    "adeq = run_nsga_with_adequecy(test_cases, adequacy_scores, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'data/experiment_result'\n",
    "for pkl_file in os.listdir(datadir):\n",
    "        if pkl_file.endswith('adeq.pkl'):\n",
    "            with open(os.path.join(datadir, pkl_file), 'rb') as f: # load pickle file for projects from merged_data\n",
    "                adeq_res  = pickle.load(f)\n",
    "        elif pkl_file.endswith('flip.pkl'):\n",
    "            with open(os.path.join(datadir, pkl_file), 'rb') as f: # load pickle file for projects from merged_data\n",
    "               bitflip_res = pickle.load(f)\n",
    "            plt.scatter(bitflip_res[:, 0], bitflip_res[:, 1], label=\"Bitflip\")\n",
    "            plt.scatter(adeq_res[:, 0], adeq_res[:, 1], label=\"Adequacy\")\n",
    "            plt.xlabel(\"TET\")\n",
    "            plt.ylabel(\"FDR\")\n",
    "            plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitflip_res = np.abs(bitflip.F)\n",
    "# adeq_res = np.abs(adeq.F)\n",
    "\n",
    "# plt.scatter(bitflip_res[:, 0], bitflip_res[:, 1], label=\"Bitflip\")\n",
    "# plt.scatter(adeq_res[:, 0], adeq_res[:, 1], label=\"Adequacy\")\n",
    "# plt.xlabel(\"TET\")\n",
    "# plt.ylabel(\"FDR\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/experiment_result/f_cov_m_all/Chart_1_bitflip.pkl', 'rb') as f:\n",
    "#     bitflip = pickle.load(f)\n",
    "\n",
    "# with open('data/experiment_result/f_cov_m_cov/Chart_1_adeq.pkl', 'rb') as f:\n",
    "#     adeq = pickle.load(f)\n",
    "# # print(data.F)\n",
    "\n",
    "# bitflip_res = bitflip_res = np.abs(bitflip.F)\n",
    "# adeq_res = np.abs(adeq.F)\n",
    "\n",
    "# plt.scatter(bitflip_res[:, 0], bitflip_res[:, 1], label=\"Bitflip\")\n",
    "# plt.scatter(adeq_res[:, 0], adeq_res[:, 1], label=\"Adequacy\")\n",
    "# plt.xlabel(\"TET\")\n",
    "# plt.ylabel(\"Effectiveness\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_fdr_m_cov\n",
      "f_fdr_m_cov\n",
      "{'JacksonCore_26': {'adeq': 1.9059999999999997, 'bigflip': 1.8890000000000002}, 'Chart_1': {'adeq': 2.316, 'bigflip': 2.0709999999999997}, 'Lang_1': {'adeq': 0.09400000000000001, 'bigflip': 0.11699999999999999}, 'Csv_16': {'adeq': 0.21, 'bigflip': 0.05500000000000001}, 'Time_1': {'adeq': 1.624, 'bigflip': 1.5510000000000002}, 'Cli_40': {'adeq': 0.0, 'bigflip': 0.0}, 'JxPath_22': {'adeq': 1.113, 'bigflip': 1.2150000000000003}}\n",
      "f_fdr_m_fdr\n",
      "f_fdr_m_fdr\n",
      "{'JacksonCore_26': {'adeq': 1.6059999999999999, 'bigflip': 1.8890000000000002}, 'Chart_1': {'adeq': 2.065, 'bigflip': 2.0709999999999997}, 'Lang_1': {'adeq': 0.121, 'bigflip': 0.11699999999999999}, 'Csv_16': {'adeq': 0.429, 'bigflip': 0.05500000000000001}, 'Time_1': {'adeq': 2.9210000000000003, 'bigflip': 1.5510000000000002}, 'Cli_40': {'adeq': 0.0, 'bigflip': 0.0}, 'JxPath_22': {'adeq': 2.0250000000000004, 'bigflip': 1.2150000000000003}}\n",
      "f_fdr_m_flc\n",
      "f_fdr_m_flc\n",
      "{'JacksonCore_26': {'adeq': 2.2540000000000004, 'bigflip': 1.8890000000000002}, 'Chart_1': {'adeq': 2.247, 'bigflip': 2.0709999999999997}, 'Lang_1': {'adeq': 0.183, 'bigflip': 0.11699999999999999}, 'Csv_16': {'adeq': 0.145, 'bigflip': 0.05500000000000001}, 'Time_1': {'adeq': 1.653, 'bigflip': 1.5510000000000002}, 'Cli_40': {'adeq': array([[ 0.078     , -7.32222222]]), 'bigflip': 0.0}, 'JxPath_22': {'adeq': 1.3530000000000002, 'bigflip': 1.2150000000000003}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(tet_dict)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/experiment_result/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/min_tet_with_failing_tests.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtet_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "types = [\n",
    "    # 'f_cov_m_cov',\n",
    "    # 'f_cov_m_fdr',\n",
    "    # 'f_cov_m_flc',\n",
    "    # 'f_cov_m_latest',\n",
    "    'f_fdr_m_cov',\n",
    "    'f_fdr_m_fdr',\n",
    "    'f_fdr_m_flc',\n",
    "    # 'f_fdr_m_latest'\n",
    "]\n",
    "\n",
    "tet_dict = {}\n",
    "for type in types:\n",
    "    print(type)\n",
    "    for target in os.listdir('./data/merged_data'):\n",
    "        pid, vid = os.path.splitext(target)[0].split('_')\n",
    "\n",
    "        with open(f'data/experiment_result/{type}/{pid}_{vid}_bitflip.pkl', 'rb') as f:\n",
    "            bitflip = pickle.load(f)\n",
    "\n",
    "        with open(f'data/experiment_result/{type}/{pid}_{vid}_adeq.pkl', 'rb') as f:\n",
    "            adeq = pickle.load(f)\n",
    "\n",
    "        with open(f'data/merged_data/{pid}_{vid}.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        with open(f\"data/failing_tests/{pid}-{vid}/failing_tests\", \"r\") as f:\n",
    "            failing_tests = f.readlines()\n",
    "\n",
    "        min_id_adeq = None\n",
    "        for i, sol in enumerate(adeq.X):\n",
    "            # print(data.index[sol].shape)\n",
    "            selected_tests = data.index[sol]\n",
    "            if all(test in selected_tests for test in failing_tests):\n",
    "                tet = adeq.F[i, 0]\n",
    "                if min_id_adeq == None:\n",
    "                    min_id_adeq = i\n",
    "                elif tet < adeq.F[min_id_adeq, 0]:\n",
    "                    min_id_adeq = i\n",
    "\n",
    "        min_id_bitflip = None\n",
    "        for i, sol in enumerate(bitflip.X):\n",
    "            # print(data.index[sol].shape)\n",
    "            selected_tests = data.index[sol]\n",
    "            if all(test in selected_tests for test in failing_tests):\n",
    "                tet = bitflip.F[i, 0]\n",
    "                if min_id_bitflip == None:\n",
    "                    min_id_bitflip = i\n",
    "                elif tet < bitflip.F[min_id_bitflip, 0]:\n",
    "                    min_id_bitflip = i\n",
    "\n",
    "        # print(\"Adeq tet\")\n",
    "        # print(adeq.F[min_id_adeq, 0])\n",
    "        # print(\"Bitflip tet\")\n",
    "        # print(bitflip.F[min_id_bitflip, 0])\n",
    "        # print(\"\\n\")\n",
    "        tet_dict[f\"{pid}_{vid}\"] = {\"adeq\": adeq.F[min_id_adeq, 0], \"bigflip\": bitflip.F[min_id_bitflip, 0]}\n",
    "    # with\n",
    "    print(type)\n",
    "    print(tet_dict)\n",
    "    with open(f\"./data/experiment_result/{type}/min_tet_with_failing_tests.json\", 'w') as f:\n",
    "        json.dump(tet_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
